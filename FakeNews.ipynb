{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "01beebdb",
      "metadata": {
        "id": "01beebdb"
      },
      "source": [
        "# EE 344 — Assignment 4: Fake News Classification\n",
        "\n",
        "In this assignment, you will classify news articles as **fake vs real** using **text features**.\n",
        "Your tasks for this assignment are as follows:\n",
        "\n",
        "1. Learn how to extract text features by vectorizing textual inputs using **CountVectorizer (Bag-of-Words)**.\n",
        "2. Implement **7 classifiers**: Logistic Regression, Perceptron, Linear SVM (LinearSVC), Multinomial Naive Bayes, KNN, Decision Tree, and Random Forest.\n",
        "3. Evaluate **train and test** performance using **accuracy, precision, recall, and F1-score**.\n",
        "4. Provide brief answers to discussion questions about (i) the text feature extraction method you implemented and (ii) the effect of using two different KNN distance choices (**Euclidean vs cosine**).\n",
        "\n",
        "\n",
        "## Submission guidelines\n",
        "- Complete all **[TODO]** blocks in this notebook.\n",
        "- Push the finished notebook to your GitHub repository.\n",
        "- Submit the GitHub link on the Canvas submission page.\n",
        "\n",
        "\n",
        "**Dataset source (for reference only):**  \n",
        "Do **not** download data from the link below. Use the provided `evaluation.csv` file that comes with this assignment.\n",
        "#### https://www.kaggle.com/datasets/aadyasingh55/fake-news-classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0944b7",
      "metadata": {
        "id": "df0944b7"
      },
      "source": [
        "## Setup\n",
        "Run the next cell to import libraries and define helper functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "125eae54",
      "metadata": {
        "id": "125eae54"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    \"\"\"Return (accuracy, precision, recall, f1).\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Use 'binary' for binary classification, otherwise fallback to macro.\n",
        "    avg = \"binary\" if len(np.unique(y_true)) == 2 else \"macro\"\n",
        "\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=avg, zero_division=0\n",
        "    )\n",
        "    return acc, prec, rec, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83ee37a",
      "metadata": {
        "id": "c83ee37a"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Put the dataset file in the same folder as this notebook (recommended), or provide an absolute path.\n",
        "\n",
        "This dataset uses **semicolon-separated** fields and can contain extra semicolons inside the text.\n",
        "So we use a custom loader that safely reconstructs the text column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ce5700b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce5700b1",
        "outputId": "5599a8c1-5252-4d49-e537-d860c867cdc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: (7815, 4)\n",
            "Label distribution:\n",
            " label\n",
            "1    4185\n",
            "0    3630\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# === Data path ===\n",
        "# If your file has a different name/path, update it here.\n",
        "DATA_PATH = \"evaluation.csv\"   # <-- change if needed\n",
        "\n",
        "def load_semicolon_dataset(path):\n",
        "    \"\"\"\n",
        "    Handles lines like:\n",
        "    ;title;text;label\n",
        "    0;some title;some text that may contain ; ; ; ;0\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "        _ = f.readline()  # header\n",
        "        for line in f:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split(\";\")\n",
        "            if len(parts) < 4:\n",
        "                continue\n",
        "\n",
        "            idx = parts[0]\n",
        "            title = parts[1]\n",
        "            label = parts[-1]\n",
        "            text = \";\".join(parts[2:-1])  # re-join any extra ';' inside text\n",
        "            rows.append((idx, title, text, label))\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=[\"id\", \"title\", \"text\", \"label\"])\n",
        "    df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"label\"]).reset_index(drop=True)\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    return df\n",
        "\n",
        "df = load_semicolon_dataset(DATA_PATH)\n",
        "print(\"Dataset:\", df.shape)\n",
        "print(\"Label distribution:\\n\", df[\"label\"].value_counts())\n",
        "\n",
        "# Combine title + text into one string per document\n",
        "docs = (df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")).astype(str).tolist()\n",
        "y = df[\"label\"].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6df6766",
      "metadata": {
        "id": "b6df6766"
      },
      "source": [
        "## Train/test split\n",
        "\n",
        "We keep a standard **80/20** split with stratification (preserves label ratio).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d3ca0b1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ca0b1a",
        "outputId": "202c0797-21fb-4dd5-c2b7-b47868cd147a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train docs: 6252 Test docs: 1563\n"
          ]
        }
      ],
      "source": [
        "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "    docs, y,\n",
        "    test_size=0.20,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train docs:\", len(X_train_text), \"Test docs:\", len(X_test_text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39543025",
      "metadata": {
        "id": "39543025"
      },
      "source": [
        "## Case Study: Bag-of-Words Features (CountVectorizer)\n",
        "\n",
        "We need to convert text into numeric features before we can train ML models.\n",
        "\n",
        "**CountVectorizer** builds a vocabulary from the **training set** and represents each document as a vector of **counts** (one entry per vocabulary term).\n",
        "\n",
        "We will use:\n",
        "$$\n",
        "\\texttt{CountVectorizer(}\n",
        "\\texttt{lowercase=True, stop_words=\"english\", ngram_range=(1,2),}\n",
        "$$\n",
        "$$\n",
        "\\texttt{ min_df=2, max_df=0.9, max_features=10000)}\n",
        "$$\n",
        "\n",
        "**What each setting means (briefly):**\n",
        "- `lowercase=True`: convert text to lowercase before building features.\n",
        "- `stop_words=\"english\"`: remove a predefined list of common English words.\n",
        "- `ngram_range=(1,2)`: allow 1-word features and 2-word features (bigrams).\n",
        "- `min_df=2`: keep a term only if it appears in at least 2 training documents.\n",
        "- `max_df=0.9`: drop a term if it appears in more than 90% of training documents.\n",
        "- `max_features=10000`: cap the vocabulary size at 10,000 terms (after filtering).\n",
        "\n",
        "### Tiny example (just to see what it does)\n",
        "\n",
        "We will build features from 3 short documents and look at the counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "aaee0c65",
      "metadata": {
        "id": "aaee0c65"
      },
      "outputs": [],
      "source": [
        "# CountVectorizer docs (read this once before TODO 1):\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b5a2cb96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a2cb96",
        "outputId": "09f9a827-e857-40c8-e90c-bf297d309251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toy vocab: ['fake', 'fake news', 'news', 'news spreads', 'spreads']\n",
            "Toy counts (rows = docs):\n",
            " [[1 1 1 1 1]\n",
            " [1 1 1 1 1]\n",
            " [0 0 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "toy_docs = [\n",
        "    \"The FAKE news spreads fast\",\n",
        "    \"Fake news spreads\",\n",
        "    \"Real news spreads\",\n",
        "]\n",
        "\n",
        "toy_vec = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    stop_words=\"english\",\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "toy_X = toy_vec.fit_transform(toy_docs)\n",
        "\n",
        "print(\"Toy vocab:\", list(toy_vec.get_feature_names_out()))\n",
        "print(\"Toy counts (rows = docs):\\n\", toy_X.toarray())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081e3f66",
      "metadata": {
        "id": "081e3f66"
      },
      "source": [
        "## Build Bag-of-Words features\n",
        "\n",
        "Goal:\n",
        "1. Create the `CountVectorizer` using the exact settings below.\n",
        "2. Fit on the training text only.\n",
        "3. Transform both train and test text into sparse Bag-of-Words features.\n",
        "\n",
        "Notes:\n",
        "- `fit_transform` on train, then `transform` on test.\n",
        "- The output is a **sparse matrix** (CSR). That is normal for text features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a6a1edcc",
      "metadata": {
        "id": "a6a1edcc",
        "outputId": "3bcebf33-c8aa-4174-8361-74032eb59520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW shapes: (6252, 10000) (1563, 10000)\n"
          ]
        }
      ],
      "source": [
        "# --- Bag-of-Words settings ---\n",
        "MAX_FEATURES = 10000\n",
        "NGRAM_RANGE = (1, 2)\n",
        "\n",
        "## [ TODO 1 ]\n",
        "# 1) Create `vectorizer` using CountVectorizer with:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "   lowercase=True,\n",
        "   stop_words=\"english\",\n",
        "   ngram_range=NGRAM_RANGE,\n",
        "   min_df=2,\n",
        "   max_df=0.9,\n",
        "   max_features=MAX_FEATURES\n",
        ")\n",
        "#\n",
        "# 2) Fit the vectorizer on the training text, then use it to transform:\n",
        "#    - the training text into BoW features\n",
        "#    - the test text into BoW features\n",
        "#\n",
        "# (Reminder: fit on train only; do NOT fit on test.)\n",
        "#\n",
        "# Print the BoW shapes.\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "print(\"BoW shapes:\", X_train_bow.shape, X_test_bow.shape)\n",
        "\n",
        "#raise NotImplementedError(\"Complete TODO 1 above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5127e270",
      "metadata": {
        "id": "5127e270"
      },
      "source": [
        "## Models\n",
        "\n",
        "Create **7 classifiers** using the exact hyperparameters below.\n",
        "\n",
        "**Important:** For KNN in this notebook, start with **Euclidean distance**.\n",
        "\n",
        "Models to implement:\n",
        "- Logistic Regression: `solver=\"saga\"`, `max_iter=2000`, `n_jobs=-1`, `random_state=42`\n",
        "- Perceptron: `max_iter=1000`, `tol=1e-3`, `random_state=42`\n",
        "- SVM (LinearSVC): `random_state=42`\n",
        "- Naive Bayes (MultinomialNB): `alpha=1.0`\n",
        "- KNN (Euclidean): `n_neighbors=7`, `metric=\"euclidean\"`, `n_jobs=-1`\n",
        "- Decision Tree: `max_depth=40`, `random_state=42`\n",
        "- Random Forest: `n_estimators=300`, `random_state=42`, `n_jobs=-1`\n",
        "\n",
        "Put them in a dictionary named `models`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "78772066",
      "metadata": {
        "id": "78772066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14590bb7-d156-4ea0-cf3f-e8751857e165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Logistic Regression': LogisticRegression(max_iter=2000, n_jobs=-1, random_state=42, solver='saga'),\n",
              " 'Perceptron': Perceptron(random_state=42),\n",
              " 'SVM (LinearSVC)': LinearSVC(random_state=42),\n",
              " 'Naive Bayes (MultinomialNB)': MultinomialNB(),\n",
              " 'KNN (euclidean)': KNeighborsClassifier(metric='euclidean', n_jobs=-1, n_neighbors=7),\n",
              " 'Decision Tree': DecisionTreeClassifier(max_depth=40, random_state=42),\n",
              " 'Random Forest': RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "## [ TODO 2 ]\n",
        "# Build the `models` dictionary using the exact parameters above.\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        solver=\"saga\",\n",
        "        max_iter=2000,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "    \"Perceptron\": Perceptron(\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "    \"SVM (LinearSVC)\": LinearSVC(\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "    \"Naive Bayes (MultinomialNB)\": MultinomialNB(\n",
        "        alpha=1.0\n",
        "    ),\n",
        "    \"KNN (euclidean)\": KNeighborsClassifier(\n",
        "        n_neighbors=7,\n",
        "        metric=\"euclidean\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(\n",
        "        max_depth=40,\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "models\n",
        "#raise NotImplementedError(\"Complete TODO 2 above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1adacab",
      "metadata": {
        "id": "c1adacab"
      },
      "source": [
        "## Train + evaluate\n",
        "\n",
        "We will evaluate each model on:\n",
        "- **Training set**\n",
        "- **Test set**\n",
        "\n",
        "Metrics:\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1\n",
        "\n",
        "We will print a table sorted by **Test F1**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "10fdf1af",
      "metadata": {
        "id": "10fdf1af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5756e5e0-39a6-4407-95b3-a28ff465bbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Results (sorted by Test F1) ===\n",
            "                      Model Train Acc Train Prec Train Rec Train F1 Test Acc Test Prec Test Rec Test F1\n",
            "              Random Forest    1.0000     1.0000    1.0000   1.0000   0.9942    0.9964   0.9928  0.9946\n",
            "              Decision Tree    1.0000     1.0000    1.0000   1.0000   0.9904    0.9952   0.9869  0.9910\n",
            "                 Perceptron    1.0000     1.0000    1.0000   1.0000   0.9878    0.9869   0.9904  0.9887\n",
            "        Logistic Regression    0.9989     0.9997    0.9982   0.9990   0.9872    0.9869   0.9892  0.9881\n",
            "            SVM (LinearSVC)    1.0000     1.0000    1.0000   1.0000   0.9853    0.9857   0.9869  0.9863\n",
            "Naive Bayes (MultinomialNB)    0.9624     0.9684    0.9612   0.9648   0.9616    0.9642   0.9642  0.9642\n",
            "            KNN (euclidean)    0.7826     0.8905    0.6774   0.7695   0.7351    0.8555   0.6081  0.7109\n"
          ]
        }
      ],
      "source": [
        "## [ TODO 3 ]\n",
        "# Write a loop that:\n",
        "# 1) fits each model on X_train_bow, y_train\n",
        "# 2) predicts on train and test\n",
        "# 3) computes (acc, prec, rec, f1) using metrics(...)\n",
        "# 4) stores results in a list\n",
        "# 5) prints a DataFrame sorted by Test F1 (descending)\n",
        "#\n",
        "# Use the exact column names below.\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Fit\n",
        "    model.fit(X_train_bow, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_train_pred = model.predict(X_train_bow)\n",
        "    y_test_pred = model.predict(X_test_bow)\n",
        "\n",
        "    # Metrics\n",
        "    train_acc, train_prec, train_rec, train_f1 = metrics(y_train, y_train_pred)\n",
        "    test_acc, test_prec, test_rec, test_f1 = metrics(y_test, y_test_pred)\n",
        "\n",
        "    results.append([\n",
        "        name,\n",
        "        train_acc, train_prec, train_rec, train_f1,\n",
        "        test_acc, test_prec, test_rec, test_f1\n",
        "    ])\n",
        "\n",
        "\n",
        "cols = [\n",
        "    \"Model\",\n",
        "    \"Train Acc\", \"Train Prec\", \"Train Rec\", \"Train F1\",\n",
        "    \"Test Acc\", \"Test Prec\", \"Test Rec\", \"Test F1\",\n",
        "]\n",
        "\n",
        "out = pd.DataFrame(results, columns=cols).sort_values(\"Test F1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 80)\n",
        "print(\"\\n=== Results (sorted by Test F1) ===\")\n",
        "print(out.to_string(index=False, formatters={\n",
        "    \"Train Acc\": \"{:.4f}\".format,\n",
        "    \"Train Prec\": \"{:.4f}\".format,\n",
        "    \"Train Rec\": \"{:.4f}\".format,\n",
        "    \"Train F1\": \"{:.4f}\".format,\n",
        "    \"Test Acc\": \"{:.4f}\".format,\n",
        "    \"Test Prec\": \"{:.4f}\".format,\n",
        "    \"Test Rec\": \"{:.4f}\".format,\n",
        "    \"Test F1\": \"{:.4f}\".format,\n",
        "}))\n",
        "\n",
        "#raise NotImplementedError(\"Complete TODO 3 above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51e27447",
      "metadata": {
        "id": "51e27447"
      },
      "source": [
        "## Cosine distance for KNN\n",
        "\n",
        "With Bag-of-Words, each document becomes a long vector of word counts (mostly zeros).  \n",
        "To compare two documents, we need a way to measure how “close” two vectors are.\n",
        "\n",
        "Two common choices:\n",
        "\n",
        "- **Euclidean distance**: straight-line distance between two vectors.\n",
        "- **Cosine distance**: based on the angle between two vectors (uses cosine similarity under the hood).\n",
        "\n",
        "In scikit-learn, KNN uses a **distance**. Cosine distance is:\n",
        "$$\n",
        "d_{\\text{cosine}}(x, z) \\;=\\; 1 - \\cos(x, z)\n",
        "\\;=\\; 1 - \\frac{x^\\top z}{\\|x\\|_2 \\,\\|z\\|_2}\n",
        "$$\n",
        "\n",
        "(where $\\cos(x,z)$ is cosine similarity).\n",
        "\n",
        "### Tiny numeric example (no text, just vectors)\n",
        "\n",
        "Let:\n",
        "- $x = [1, 1]$\n",
        "- $z_1 = [2, 2]$  (same direction as $x$, just “bigger”)\n",
        "- $z_2 = [2, 0]$  (different direction)\n",
        "\n",
        "**Euclidean distances**\n",
        "$$\n",
        "\\|x - z_1\\|_2 = \\sqrt{(1-2)^2 + (1-2)^2} = \\sqrt{2}\n",
        "$$\n",
        "$$\n",
        "\\|x - z_2\\|_2 = \\sqrt{(1-2)^2 + (1-0)^2} = \\sqrt{2}\n",
        "$$\n",
        "So Euclidean says $z_1$ and $z_2$ are equally far from $x$ here.\n",
        "\n",
        "**Cosine distances**\n",
        "$$\n",
        "\\cos(x, z_1) = \\frac{1\\cdot 2 + 1\\cdot 2}{\\sqrt{2}\\cdot \\sqrt{8}} = 1\n",
        "\\Rightarrow d_{\\text{cosine}}(x, z_1)=0\n",
        "$$\n",
        "$$\n",
        "\\cos(x, z_2) = \\frac{1\\cdot 2 + 1\\cdot 0}{\\sqrt{2}\\cdot 2} \\approx 0.707\n",
        "\\Rightarrow d_{\\text{cosine}}(x, z_2)\\approx 0.293\n",
        "$$\n",
        "So cosine says $z_1$ is closer to $x$ than $z_2$.\n",
        "\n",
        "### What you will do\n",
        "\n",
        "Keep everything the same, but change your KNN metric from `\"euclidean\"` to `\"cosine\"`, then re-run your evaluation and compare results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "04779264",
      "metadata": {
        "id": "04779264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9a52e8-b74a-487a-c5a2-87cc8c2b5db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN (cosine) Train: (0.913147792706334, 0.8721146192624039, 0.9817801672640383, 0.9237038077841787)\n",
            "KNN (cosine) Test : (0.8797184900831734, 0.8307849133537207, 0.973715651135006, 0.8965896589658966)\n"
          ]
        }
      ],
      "source": [
        "# Tip: For cosine distance, brute-force search is commonly used.\n",
        "# Example (do not run until TODO 2/3 are done):\n",
        "#\n",
        "knn_cos = KNeighborsClassifier(\n",
        "    n_neighbors=7,\n",
        "    metric=\"cosine\",\n",
        "    algorithm=\"brute\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "knn_cos.fit(X_train_bow, y_train)\n",
        "\n",
        "y_train_pred = knn_cos.predict(X_train_bow)\n",
        "y_test_pred = knn_cos.predict(X_test_bow)\n",
        "\n",
        "print(\"KNN (cosine) Train:\", metrics(y_train, y_train_pred))\n",
        "print(\"KNN (cosine) Test :\", metrics(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace5e4ac",
      "metadata": {
        "id": "ace5e4ac"
      },
      "source": [
        "## Discussion questions (answer in your own words)\n",
        "\n",
        "Write short answers below (2–5 sentences each is enough).\n",
        "\n",
        "### Question A\n",
        "In your own words, what is the added value of allowing 2-word sequences (bigrams) in `ngram_range`?\n",
        "\n",
        "### Question B\n",
        "In your own words, why might someone choose to set both `min_df` and `max_df` when building the vocabulary?\n",
        "\n",
        "### Question C\n",
        "\n",
        "After you run KNN with **Euclidean** and then with **Cosine** distance:\n",
        "\n",
        "- Do you observe any difference in results?\n",
        "- If yes, why do you think the difference happens (your intuition)?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d04ee569",
      "metadata": {
        "id": "d04ee569"
      },
      "source": [
        "**Your answers:**\n",
        "\n",
        "- **A:**  \n",
        "  Allowing two-word sequences allows the model to capture not only isolated words but also short phrases. There are many important applications of this, namely in fake news detection where meaning can be denoted by specific combinations of words.\n",
        "\n",
        "- **B:**  \n",
        "  Someone may choose to set both when building the vocabulary since they do different things. While the `min_df` threshhold removes noise, the `max_df` removes common terms that don't separate themselves.\n",
        "\n",
        "- **C:**  \n",
        "  Yes, I do observe differences, namely cosine performing better than euclidean. I think this happens because cosine focuses on the direction of the vectors as opposed to their magnitudes. Euclidean is influenced by document length as well, when compared to cosine which is better at capturing similarity in phrases.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}